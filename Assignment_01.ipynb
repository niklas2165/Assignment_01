{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and Data Loading"
      ],
      "metadata": {
        "id": "xsQbCN_Wp1Cm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Imports and Data Loading\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Load the \"train.csv\" data\n",
        "# ----------------------------------------------------------\n",
        "train_data = pd.read_csv('train.csv')\n",
        "\n",
        "# Print out column names for reference\n",
        "print(\"Columns in train.csv:\")\n",
        "print(train_data.columns)\n",
        "\n",
        "# We'll pick a handful of numeric features and SalePrice.\n",
        "train_data = train_data[['LotFrontage', 'LotArea', 'PoolArea',\n",
        "                         'OverallQual', 'OverallCond', 'YearBuilt',\n",
        "                         'GarageArea', 'YrSold', 'SalePrice']]\n",
        "\n",
        "# Feature Selection: The selected features provide insights with respect to size,\n",
        "# condition and amenities of the respective properties. Hence, we believe those\n",
        "# features are key to predict the target variable price.\n",
        "\n",
        "# Drop rows with missing data (simple approach)\n",
        "train_data.dropna(inplace=True)\n",
        "print(\"Shape after dropping NAs:\", train_data.shape)\n",
        "\n",
        "# Optional peek at the data\n",
        "train_data.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "collapsed": true,
        "id": "ynLslIHtp5CI",
        "outputId": "bb5274bb-9c13-4b02-d572-e0859b63111f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in train.csv:\n",
            "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
            "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
            "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
            "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
            "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
            "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
            "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
            "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
            "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
            "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
            "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
            "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
            "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
            "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
            "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
            "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
            "       'SaleCondition', 'SalePrice'],\n",
            "      dtype='object')\n",
            "Shape after dropping NAs: (1201, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   LotFrontage  LotArea  PoolArea  OverallQual  OverallCond  YearBuilt  \\\n",
              "0         65.0     8450         0            7            5       2003   \n",
              "1         80.0     9600         0            6            8       1976   \n",
              "2         68.0    11250         0            7            5       2001   \n",
              "3         60.0     9550         0            7            5       1915   \n",
              "4         84.0    14260         0            8            5       2000   \n",
              "\n",
              "   GarageArea  YrSold  SalePrice  \n",
              "0         548    2008     208500  \n",
              "1         460    2007     181500  \n",
              "2         608    2008     223500  \n",
              "3         642    2006     140000  \n",
              "4         836    2008     250000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8b565bf-1e36-419f-b4e9-1f92a3e988e4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>548</td>\n",
              "      <td>2008</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>460</td>\n",
              "      <td>2007</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>608</td>\n",
              "      <td>2008</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>642</td>\n",
              "      <td>2006</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>836</td>\n",
              "      <td>2008</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8b565bf-1e36-419f-b4e9-1f92a3e988e4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d8b565bf-1e36-419f-b4e9-1f92a3e988e4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d8b565bf-1e36-419f-b4e9-1f92a3e988e4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-935dbbad-61d7-408c-8c04-23cd7136a385\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-935dbbad-61d7-408c-8c04-23cd7136a385')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-935dbbad-61d7-408c-8c04-23cd7136a385 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 1201,\n  \"fields\": [\n    {\n      \"column\": \"LotFrontage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24.284751774483183,\n        \"min\": 21.0,\n        \"max\": 313.0,\n        \"num_unique_values\": 110,\n        \"samples\": [\n          150.0,\n          91.0,\n          84.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LotArea\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7924,\n        \"min\": 1300,\n        \"max\": 215245,\n        \"num_unique_values\": 869,\n        \"samples\": [\n          11198,\n          4500,\n          8544\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PoolArea\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 38,\n        \"min\": 0,\n        \"max\": 648,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          512,\n          480\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OverallQual\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1,\n          6,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OverallCond\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2,\n        \"max\": 9,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          8,\n          2,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"YearBuilt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31,\n        \"min\": 1872,\n        \"max\": 2010,\n        \"num_unique_values\": 112,\n        \"samples\": [\n          1968,\n          1987,\n          2000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GarageArea\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 221,\n        \"min\": 0,\n        \"max\": 1418,\n        \"num_unique_values\": 399,\n        \"samples\": [\n          198,\n          928,\n          308\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"YrSold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2006,\n        \"max\": 2010,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2007,\n          2010,\n          2006\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SalePrice\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 83389,\n        \"min\": 34900,\n        \"max\": 755000,\n        \"num_unique_values\": 597,\n        \"samples\": [\n          372402,\n          395192,\n          315000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train/Validation Split"
      ],
      "metadata": {
        "id": "Z0sW2z-pqA98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Train/Validation Split --> preparing data for training and testing\n",
        "\n",
        "# We'll do an 80/20 split within train.csv to create internal train/val sets:\n",
        "X_train_val = train_data.drop('SalePrice', axis=1).values  # all but SalePrice\n",
        "y_train_val = train_data['SalePrice'].values               # target only\n",
        "\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Shapes:\")\n",
        "print(\"  X_train_split:\", X_train_split.shape)\n",
        "print(\"  X_val_split:  \", X_val_split.shape)\n",
        "print(\"  y_train_split:\", y_train_split.shape)\n",
        "print(\"  y_val_split:  \", y_val_split.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnkDixxlqEgU",
        "outputId": "cd2e7ae5-e22f-475a-801a-8a20bccdd6ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes:\n",
            "  X_train_split: (960, 8)\n",
            "  X_val_split:   (241, 8)\n",
            "  y_train_split: (960,)\n",
            "  y_val_split:   (241,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Scaling"
      ],
      "metadata": {
        "id": "vDW12aBKqI1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Feature Scaling (MinMaxScaler)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train_split_scaled = scaler.fit_transform(X_train_split)  # fit on train split\n",
        "X_val_split_scaled   = scaler.transform(X_val_split)        # transform val split\n",
        "\n",
        "# prevents features with larger values from dominating the learning process\n"
      ],
      "metadata": {
        "id": "sxlqYXnQqMHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Dataset & DataLoader"
      ],
      "metadata": {
        "id": "TGgAwqK6qO8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Convert NumPy arrays to PyTorch tensors and create DataLoaders\n",
        "# --> convert data into PyTorch format\n",
        "\n",
        "# Convert to tensors\n",
        "X_train_t = torch.tensor(X_train_split_scaled, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train_split,        dtype=torch.float32)\n",
        "\n",
        "X_val_t   = torch.tensor(X_val_split_scaled,   dtype=torch.float32)\n",
        "y_val_t   = torch.tensor(y_val_split,          dtype=torch.float32)\n",
        "\n",
        "# Create TensorDatasets\n",
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "val_dataset   = TensorDataset(X_val_t,   y_val_t)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True) # provides batches of training data in a randomized order for each training epoch\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=32, shuffle=False)\n",
        "\n",
        "# Creates an iterator over the training dataset with mini-batches of 32 examples;\n",
        "# shuffle=True randomizes the order for each epoch."
      ],
      "metadata": {
        "id": "prYvBpPpqSmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning Snippet"
      ],
      "metadata": {
        "id": "SXvXIhcSqWYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Hyperparameter Tuning Snippet\n",
        "\n",
        "# -- A function that builds a simple MLP with two hidden layers:\n",
        "def build_mlp(input_dim, hidden1=64, hidden2=32):  # input dim --> number of input features\n",
        "    return nn.Sequential(               # combines all the layers into a single model\n",
        "        nn.Linear(input_dim, hidden1),  # hidden layer\n",
        "        nn.ReLU(),                      # activation function --> introduces non-linearity\n",
        "        nn.Linear(hidden1, hidden2),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden2, 1)\n",
        "    )\n",
        "\n",
        "# -- A function to train and evaluate for a fixed number of epochs:\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=20): # epochs --> number of times the model will see the entire training dataset\n",
        "    train_loss_history = []\n",
        "    val_loss_history   = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "# goes through the training data, calculates how far off the model's predictions are (loss), and adjusts the model's parameters to reduce this loss.\n",
        "        model.train()\n",
        "        running_train_loss = 0.0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(X_batch).squeeze()\n",
        "            loss  = criterion(preds, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_train_loss += loss.item()\n",
        "        avg_train_loss = running_train_loss / len(train_loader)\n",
        "        train_loss_history.append(avg_train_loss)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        running_val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                preds = model(X_batch).squeeze()\n",
        "                loss  = criterion(preds, y_batch)\n",
        "                running_val_loss += loss.item()\n",
        "        avg_val_loss = running_val_loss / len(val_loader)\n",
        "        val_loss_history.append(avg_val_loss)\n",
        "\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, \"\n",
        "              f\"Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    return train_loss_history, val_loss_history # function returns the loss history for both training and validation\n",
        "\n",
        "# -- Perform a small grid search over certain hyperparameters:\n",
        "criterion = nn.MSELoss()\n",
        "input_size = X_train_t.shape[1]  # number of features in X\n",
        "\n",
        "search_hidden1 = [32, 64]        # possible hidden layer1 sizes\n",
        "search_lr      = [0.01, 0.001]   # possible learning rates\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "best_config   = None\n",
        "\n",
        "# We loop over a few combinations: few possible choices for a key hyperparameter: the size of the first hidden layer (`hidden1`) and the learning rate (`LR`)\n",
        "for h1 in search_hidden1:\n",
        "    for lr in search_lr:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(f\"Testing config: hidden1={h1}, hidden2=32, LR={lr}\")\n",
        "\n",
        "        # Build a fresh model for each config\n",
        "        model_test = build_mlp(input_dim=input_size, hidden1=h1, hidden2=32)\n",
        "        optimizer_test = optim.Adam(model_test.parameters(), lr=lr)\n",
        "\n",
        "        # Train & Evaluate\n",
        "        train_hist, val_hist = train_model(\n",
        "            model_test, train_loader, val_loader, criterion, optimizer_test, epochs=20\n",
        "        )\n",
        "\n",
        "        final_val_loss = val_hist[-1]  # last epoch's val loss\n",
        "        if final_val_loss < best_val_loss:\n",
        "            best_val_loss = final_val_loss\n",
        "            best_config   = (h1, 32, lr)\n",
        "\n",
        "print(\"\\nBest hyperparam config found:\") # the lowest validation loss is selected as the \"best\" setting\n",
        "print(f\"hidden1={best_config[0]}, hidden2={best_config[1]}, learning_rate={best_config[2]}\")\n",
        "print(f\"Validation Loss: {best_val_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie1NQbllqcUn",
        "outputId": "619bd90a-2d28-4c86-9831-29376a957902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Testing config: hidden1=32, hidden2=32, LR=0.01\n",
            "Epoch 1/20, Train Loss: 38107287825.0667, Val Loss: 45427358720.0000\n",
            "Epoch 2/20, Train Loss: 38022901691.7333, Val Loss: 45195121920.0000\n",
            "Epoch 3/20, Train Loss: 37535139976.5333, Val Loss: 44220363520.0000\n",
            "Epoch 4/20, Train Loss: 36068728695.4667, Val Loss: 41793446144.0000\n",
            "Epoch 5/20, Train Loss: 32989254997.3333, Val Loss: 37371179008.0000\n",
            "Epoch 6/20, Train Loss: 28068193962.6667, Val Loss: 30846944768.0000\n",
            "Epoch 7/20, Train Loss: 21569423223.4667, Val Loss: 23103262720.0000\n",
            "Epoch 8/20, Train Loss: 14706170931.2000, Val Loss: 15611639296.0000\n",
            "Epoch 9/20, Train Loss: 9056091912.5333, Val Loss: 10125450880.0000\n",
            "Epoch 10/20, Train Loss: 5776192618.6667, Val Loss: 7319688832.0000\n",
            "Epoch 11/20, Train Loss: 4547808904.5333, Val Loss: 6354382528.0000\n",
            "Epoch 12/20, Train Loss: 4254514252.8000, Val Loss: 6097164096.0000\n",
            "Epoch 13/20, Train Loss: 4190179443.2000, Val Loss: 5978212064.0000\n",
            "Epoch 14/20, Train Loss: 4150438199.4667, Val Loss: 5913892544.0000\n",
            "Epoch 15/20, Train Loss: 4105631662.9333, Val Loss: 5862437568.0000\n",
            "Epoch 16/20, Train Loss: 4064617228.8000, Val Loss: 5833157440.0000\n",
            "Epoch 17/20, Train Loss: 4023466568.5333, Val Loss: 5771401248.0000\n",
            "Epoch 18/20, Train Loss: 3982417412.2667, Val Loss: 5702329760.0000\n",
            "Epoch 19/20, Train Loss: 3943495820.8000, Val Loss: 5630183296.0000\n",
            "Epoch 20/20, Train Loss: 3902237994.6667, Val Loss: 5592898432.0000\n",
            "\n",
            "==================================================\n",
            "Testing config: hidden1=32, hidden2=32, LR=0.001\n",
            "Epoch 1/20, Train Loss: 38111874252.8000, Val Loss: 45448291328.0000\n",
            "Epoch 2/20, Train Loss: 38111562547.2000, Val Loss: 45447808768.0000\n",
            "Epoch 3/20, Train Loss: 38110866500.2667, Val Loss: 45446649344.0000\n",
            "Epoch 4/20, Train Loss: 38109284420.2667, Val Loss: 45444208896.0000\n",
            "Epoch 5/20, Train Loss: 38106244437.3333, Val Loss: 45439887104.0000\n",
            "Epoch 6/20, Train Loss: 38101191065.6000, Val Loss: 45432946176.0000\n",
            "Epoch 7/20, Train Loss: 38093499118.9333, Val Loss: 45422810880.0000\n",
            "Epoch 8/20, Train Loss: 38082580206.9333, Val Loss: 45408661248.0000\n",
            "Epoch 9/20, Train Loss: 38067661550.9333, Val Loss: 45389879808.0000\n",
            "Epoch 10/20, Train Loss: 38048166980.2667, Val Loss: 45365959936.0000\n",
            "Epoch 11/20, Train Loss: 38023769088.0000, Val Loss: 45335927296.0000\n",
            "Epoch 12/20, Train Loss: 37993738035.2000, Val Loss: 45299578112.0000\n",
            "Epoch 13/20, Train Loss: 37957456145.0667, Val Loss: 45256648960.0000\n",
            "Epoch 14/20, Train Loss: 37914796032.0000, Val Loss: 45205910272.0000\n",
            "Epoch 15/20, Train Loss: 37865120221.8667, Val Loss: 45147169792.0000\n",
            "Epoch 16/20, Train Loss: 37808013312.0000, Val Loss: 45080211968.0000\n",
            "Epoch 17/20, Train Loss: 37742945757.8667, Val Loss: 45004790016.0000\n",
            "Epoch 18/20, Train Loss: 37669947392.0000, Val Loss: 44919499264.0000\n",
            "Epoch 19/20, Train Loss: 37588054562.1333, Val Loss: 44824946944.0000\n",
            "Epoch 20/20, Train Loss: 37497395609.6000, Val Loss: 44720403456.0000\n",
            "\n",
            "==================================================\n",
            "Testing config: hidden1=64, hidden2=32, LR=0.01\n",
            "Epoch 1/20, Train Loss: 38104423833.6000, Val Loss: 45412099584.0000\n",
            "Epoch 2/20, Train Loss: 37961431040.0000, Val Loss: 45023150080.0000\n",
            "Epoch 3/20, Train Loss: 37179519112.5333, Val Loss: 43475162112.0000\n",
            "Epoch 4/20, Train Loss: 34869183283.2000, Val Loss: 39763403520.0000\n",
            "Epoch 5/20, Train Loss: 30286542779.7333, Val Loss: 33234561792.0000\n",
            "Epoch 6/20, Train Loss: 23371085619.2000, Val Loss: 24552498304.0000\n",
            "Epoch 7/20, Train Loss: 15416970615.4667, Val Loss: 15730540736.0000\n",
            "Epoch 8/20, Train Loss: 8775734673.0667, Val Loss: 9527469952.0000\n",
            "Epoch 9/20, Train Loss: 5308906188.8000, Val Loss: 6834259968.0000\n",
            "Epoch 10/20, Train Loss: 4356162478.9333, Val Loss: 6132131968.0000\n",
            "Epoch 11/20, Train Loss: 4201466730.6667, Val Loss: 5999369952.0000\n",
            "Epoch 12/20, Train Loss: 4151105826.1333, Val Loss: 5906406656.0000\n",
            "Epoch 13/20, Train Loss: 4104438963.2000, Val Loss: 5853632288.0000\n",
            "Epoch 14/20, Train Loss: 4059223168.0000, Val Loss: 5779750592.0000\n",
            "Epoch 15/20, Train Loss: 4007760874.6667, Val Loss: 5738655200.0000\n",
            "Epoch 16/20, Train Loss: 3965256537.6000, Val Loss: 5689476864.0000\n",
            "Epoch 17/20, Train Loss: 3920905612.8000, Val Loss: 5599860448.0000\n",
            "Epoch 18/20, Train Loss: 3868261730.1333, Val Loss: 5531463872.0000\n",
            "Epoch 19/20, Train Loss: 3826103598.9333, Val Loss: 5445858304.0000\n",
            "Epoch 20/20, Train Loss: 3781490833.0667, Val Loss: 5422314208.0000\n",
            "\n",
            "==================================================\n",
            "Testing config: hidden1=64, hidden2=32, LR=0.001\n",
            "Epoch 1/20, Train Loss: 38111998020.2667, Val Loss: 45448465408.0000\n",
            "Epoch 2/20, Train Loss: 38111775948.8000, Val Loss: 45448100096.0000\n",
            "Epoch 3/20, Train Loss: 38111209949.8667, Val Loss: 45447105280.0000\n",
            "Epoch 4/20, Train Loss: 38109785429.3333, Val Loss: 45444781824.0000\n",
            "Epoch 5/20, Train Loss: 38106782378.6667, Val Loss: 45440311040.0000\n",
            "Epoch 6/20, Train Loss: 38101384123.7333, Val Loss: 45432818688.0000\n",
            "Epoch 7/20, Train Loss: 38092936396.8000, Val Loss: 45421269760.0000\n",
            "Epoch 8/20, Train Loss: 38080325085.8667, Val Loss: 45404635648.0000\n",
            "Epoch 9/20, Train Loss: 38062376413.8667, Val Loss: 45382026752.0000\n",
            "Epoch 10/20, Train Loss: 38038578722.1333, Val Loss: 45352230144.0000\n",
            "Epoch 11/20, Train Loss: 38008087552.0000, Val Loss: 45314668544.0000\n",
            "Epoch 12/20, Train Loss: 37970324275.2000, Val Loss: 45268593920.0000\n",
            "Epoch 13/20, Train Loss: 37924415488.0000, Val Loss: 45213435648.0000\n",
            "Epoch 14/20, Train Loss: 37869764198.4000, Val Loss: 45148796672.0000\n",
            "Epoch 15/20, Train Loss: 37805993574.4000, Val Loss: 45073498624.0000\n",
            "Epoch 16/20, Train Loss: 37732584038.4000, Val Loss: 44986673152.0000\n",
            "Epoch 17/20, Train Loss: 37648559308.8000, Val Loss: 44888465664.0000\n",
            "Epoch 18/20, Train Loss: 37553420424.5333, Val Loss: 44778897408.0000\n",
            "Epoch 19/20, Train Loss: 37447670510.9333, Val Loss: 44655047168.0000\n",
            "Epoch 20/20, Train Loss: 37329621674.6667, Val Loss: 44518742016.0000\n",
            "\n",
            "Best hyperparam config found:\n",
            "hidden1=64, hidden2=32, learning_rate=0.01\n",
            "Validation Loss: 5422314208.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tests different versions of your neural network (changing some key settings) to see which one performs best on the validation data. This helps you choose the most effective model setup before training the final model."
      ],
      "metadata": {
        "id": "bVk0kFFSHYGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the Final Model & Train with Chosen Hyperparameters"
      ],
      "metadata": {
        "id": "bIG61cHPqkDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) Define final model using best hyperparams from the snippet\n",
        "\n",
        "best_h1 = 64\n",
        "best_h2 = 32\n",
        "best_lr = 0.01\n",
        "\n",
        "final_model = build_mlp(input_dim=input_size, hidden1=best_h1, hidden2=best_h2)\n",
        "final_optimizer = optim.Adam(final_model.parameters(), lr=best_lr) # # We use the Adam optimizer which will adjust our model's weights during training.\n",
        "\n",
        "\n",
        "# Retrain from scratch with these best hyperparameters (e.g., 50 epochs)\n",
        "train_losses = []\n",
        "val_losses   = []\n",
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # TRAIN\n",
        "    final_model.train()\n",
        "    epoch_train_loss = 0.0\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        final_optimizer.zero_grad()\n",
        "        preds = final_model(batch_x).squeeze()\n",
        "        loss  = criterion(preds, batch_y)\n",
        "        loss.backward()                         # Backpropagate the error to compute gradients\n",
        "        final_optimizer.step()                  # Update model weights using the optimizer\n",
        "        epoch_train_loss += loss.item()\n",
        "    epoch_train_loss /= len(train_loader)\n",
        "    train_losses.append(epoch_train_loss)\n",
        "\n",
        "    # VALIDATION\n",
        "    # evaluates the model's performance on the validation set after each training epoch\n",
        "    final_model.eval()\n",
        "    epoch_val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in val_loader:\n",
        "            val_preds = final_model(batch_x).squeeze()\n",
        "            val_loss  = criterion(val_preds, batch_y)\n",
        "            epoch_val_loss += val_loss.item()\n",
        "    epoch_val_loss /= len(val_loader)\n",
        "    val_losses.append(epoch_val_loss)\n",
        "\n",
        "    # Print progress every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9H0Sj_0bqsXR",
        "outputId": "82ff2dc5-ee0e-419f-c6a6-5740a1218410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/50] Train Loss: 4181683392.0000, Val Loss: 5949263936.0000\n",
            "Epoch [20/50] Train Loss: 3647589367.4667, Val Loss: 5242101408.0000\n",
            "Epoch [30/50] Train Loss: 3183036049.0667, Val Loss: 4618064592.0000\n",
            "Epoch [40/50] Train Loss: 2833802990.9333, Val Loss: 4043859376.0000\n",
            "Epoch [50/50] Train Loss: 2585793403.7333, Val Loss: 3670067744.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Takes the best settings found during hyperparameter tuning, builds a final model with those settings, trains it on your data, and then checks how well it performs."
      ],
      "metadata": {
        "id": "ijnUuAIDJt8q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Training & Validation Loss of Final Model"
      ],
      "metadata": {
        "id": "IRpEMN-nrAmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7) Plot the final model's training & validation loss curves\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses,   label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('Final Model - Training & Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "Om0SMvVlrBrH",
        "outputId": "abc77a46-cb7f-4c0d-8889-5896762baa49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqYAAAGJCAYAAABYafHhAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWpRJREFUeJzt3Xd4U2X/BvD7ZHemezFboIxSKksFZEiBgsgSBbEoBX0dgII4cbD0J4qiOAB9UeF1MRUVFBHZIiqChQpYihSorLK6R5rk/P44SZq0BVqa9iTp/bmucyU55+Tkm54G7j7neZ4IoiiKICIiIiKSmULuAoiIiIiIAAZTIiIiInIRDKZERERE5BIYTImIiIjIJTCYEhEREZFLYDAlIiIiIpfAYEpERERELoHBlIiIiIhcAoMpEREREbkEBlOi63D8+HEIgoBly5bV6es0b94cKSkpdfoatZGSkoLmzZtf13P79OmDPn36OLWe+iAIAmbNmnVdz3X18ymHqn6HqvsznjVrFgRBcGo927ZtgyAI2LZtm1OPS0TVw2BKVIVly5ZBEIQql2effVbu8iqx1vbAAw9Uuf3555+37XPhwoV6rq7uXe182S/XG6I9xb///ou7774bYWFh8Pf3x0033VTtP6727dsHQRDwwgsvXHGfjIwMCIKAadOmOaniurNo0aI6/8Oypvr06YP27dvLXQaRrFRyF0DkyubMmYPo6GiHde3bt0ezZs1QXFwMtVotU2WV6XQ6fPnll1i0aBE0Go3DtuXLl0On06GkpESm6upWr1698Omnnzqse+CBB3DjjTfiwQcftK3z9fWt9WsVFxdDpbq+fzrT09OhUMjTHmA2mzF06FAcOXIEU6dORVRUFH7//XesXLmyWq24nTp1Qps2bbB8+XK8/PLLVe7zxRdfAADGjh1bq1pr8zOurkWLFiEkJKTSe+/VqxeKi4srfYaIqH4wmBJdxaBBg9ClS5cqt+l0unqu5uoGDhyIb7/9Fhs2bMCwYcNs63/55RdkZmZi5MiR+PLLL2WssO7ExMQgJibGYd3DDz+MmJiYq4Yko9EIs9lcoxBSm/Ou1Wqv+7m1lZ6ejj///BPz5s3DU089BQCYOHEiSktLq32M5ORkvPjii/j1119x8803V9q+fPlytGnTBp06dapVrXJ+thQKhct9tokaEl7KJ7oOVfUxTUlJga+vL06dOoXhw4fD19cXoaGhePLJJ2EymRye/8Ybb6B79+4IDg6Gl5cXOnfujDVr1tSqpkaNGqFXr162Viurzz//HPHx8Ve8RLh69Wp07twZXl5eCAkJwdixY3Hq1KlK+3399ddo3749dDod2rdvj7Vr11Z5PLPZjAULFiAuLg46nQ7h4eF46KGHcPny5Vq9v9qynrM33ngDCxYsQIsWLaDVanHo0CEYDAbMmDEDnTt3hl6vh4+PD3r27ImtW7dWOk7F/o/Wfo5Hjx5FSkoKAgICoNfrMX78eBQVFTk8t2IfU2sXhF27dmHatGkIDQ2Fj48PRowYgfPnzzs812w2Y9asWYiKioK3tzduvfVWHDp0qNr9Vq0ttaIoOqyvSVhOTk4GgEq/YwCwd+9epKen2/b55ptvMHjwYERFRUGr1aJFixZ46aWXKn0WqlJVH9Off/4ZXbt2hU6nQ4sWLfDBBx9U+dylS5eib9++CAsLg1arRbt27bB48WKHfZo3b46DBw9i+/bttm4e1v7OV+pjWp3PSU3+DaiNRYsWIS4uDlqtFlFRUZg0aRJycnIc9snIyMDIkSMREREBnU6Hxo0b4+6770Zubq5tn02bNuGWW25BQEAAfH190bp1azz33HNOq5PoerDFlOgqcnNzK/XJDAkJueL+JpMJSUlJuOmmm/DGG2/gp59+wvz589GiRQs88sgjtv3efvttDB06FMnJyTAYDFixYgXuuusurF+/HoMHD77ueu+55x5MmTIFBQUF8PX1hdFoxOrVqzFt2rQqL+MvW7YM48ePR9euXTF37lycO3cOb7/9Nnbt2oU///wTAQEBAIAff/wRI0eORLt27TB37lxcvHgR48ePR+PGjSsd86GHHrId97HHHkNmZibee+89/Pnnn9i1a5fs3R+WLl2KkpISPPjgg9BqtQgKCkJeXh4+/PBDjBkzBv/5z3+Qn5+Pjz76CElJSfj9999xww03XPO4o0aNQnR0NObOnYt9+/bhww8/RFhYGF577bVrPvfRRx9FYGAgZs6ciePHj2PBggWYPHkyVq5cadtn+vTpmDdvHoYMGYKkpCTs378fSUlJ1e6e0bp1a3Tv3h3z58/H3XffjaZNm1brefaio6PRvXt3rFq1Cm+99RaUSqVtmzWs3nPPPQCk3y1fX19MmzYNvr6+2LJlC2bMmIG8vDy8/vrrNXrdtLQ0DBgwAKGhoZg1axaMRiNmzpyJ8PDwSvsuXrwYcXFxGDp0KFQqFdatW4eJEyfCbDZj0qRJAIAFCxbg0Ucfha+vL55//nkAqPJYVtX9nADV/zfges2aNQuzZ89Gv3798MgjjyA9PR2LFy/Gnj17bJ8vg8GApKQklJaW4tFHH0VERAROnTqF9evXIycnB3q9HgcPHsTtt9+ODh06YM6cOdBqtTh69Ch27dpV6xqJakUkokqWLl0qAqhyEUVRzMzMFAGIS5cutT1n3LhxIgBxzpw5Dsfq2LGj2LlzZ4d1RUVFDo8NBoPYvn17sW/fvg7rmzVrJo4bN+6a9QIQJ02aJF66dEnUaDTip59+KoqiKH733XeiIAji8ePHxZkzZ4oAxPPnz9teMywsTGzfvr1YXFxsO9b69etFAOKMGTNs62644QYxMjJSzMnJsa378ccfRQBis2bNbOt27twpAhA///xzh/p++OGHSut79+4t9u7d+5rv7Xr5+Pg4/Oys58zf31/Mzs522NdoNIqlpaUO6y5fviyGh4eLEyZMcFgPQJw5c6btsfXnWnG/ESNGiMHBwQ7rKp5P6+9Zv379RLPZbFv/+OOPi0ql0vbzPnv2rKhSqcThw4c7HG/WrFkigGr9jpw9e1ZMSEgQNRqN2Lp160o/g+pauHChCEDcuHGjbZ3JZBIbNWokduvWzbau4u+4KIriQw89JHp7e4slJSW2dePGjXP4HRLFyj/j4cOHizqdTjxx4oRt3aFDh0SlUilW/G+sqtdNSkoSY2JiHNbFxcVV+fu3detWEYC4detWURRr9jmpyb8BVendu7cYFxd3xe3Z2dmiRqMRBwwYIJpMJtv69957TwQgfvzxx6IoiuKff/4pAhBXr159xWO99dZbDv8eELkKXsonuoqFCxdi06ZNDsu1PPzwww6Pe/bsiWPHjjms8/Lyst2/fPkycnNz0bNnT+zbt69W9QYGBmLgwIFYvnw5AKkVq3v37mjWrFmlff/44w9kZ2dj4sSJDn3qBg8ejDZt2uC7774DAJw5cwapqakYN24c9Hq9bb/+/fujXbt2DsdcvXo19Ho9+vfvjwsXLtiWzp07w9fXt8pL4/Vt5MiRCA0NdVinVCpt/UzNZjMuXboEo9GILl26VPucVHXeL168iLy8vGs+98EHH3SY9qhnz54wmUw4ceIEAGDz5s0wGo2YOHGiw/MeffTRatVmNBoxdOhQ+Pj4IC0tDfn5+RgwYIDD5d/ly5dDEAT8888/Vz3W6NGjoVarHS7nb9++HadOnbJdxgccf8fz8/Nx4cIF9OzZE0VFRfj777+rVTcgtUBu3LgRw4cPd2jlbdu2LZKSkirtb/+61isevXv3xrFjxxwuY1dXdT8n9qrzb8D1+Omnn2AwGDB16lSHQXT/+c9/4O/vb6vF+jnduHFjpe4kVtZW3m+++QZms7nWtRE5i8cE0x07dmDIkCGIioqCIAj4+uuva/T8kpISpKSkID4+HiqVCsOHD69yv23btqFTp07QarVo2bKly003Qs514403ol+/fg7L1eh0ukqhJzAwsFL/yvXr1+Pmm2+GTqdDUFAQQkNDsXjx4uv6j7Oie+65B5s2bcLJkyfx9ddf2y6tVmQNPa1bt660rU2bNrbt1ttWrVpV2q/iczMyMpCbm4uwsDCEhoY6LAUFBcjOzq7Re7l06RLOnj1rW5zx86k4y4LV//73P3To0AE6nQ7BwcEIDQ3Fd999V+3XrHhpPDAwEACq1bf2Ws+1noOWLVs67BcUFGTb92rWrFmD33//HQsWLEBsbCw2btyI48eP47bbbkNhYSEA4K+//kJoaOgVfz5WwcHBSEpKwtq1a23dCL744guoVCqMGjXKtt/BgwcxYsQI6PV6+Pv7IzQ01DYQrSbn8fz58yguLq7W7x8A7Nq1C/369YOPjw8CAgIQGhpq6zd5Pb8/1f2cWFX334DrcaVaNBoNYmJibNujo6Mxbdo0fPjhhwgJCUFSUhIWLlzo8P5Hjx6NHj164IEHHkB4eDjuvvturFq1iiGVZOcxwbSwsBAJCQlYuHDhdT3fZDLBy8sLjz322BXDR2ZmJgYPHoxbb70VqampmDp1Kh544AFs3LixNqWTB7Hvc3clO3fuxNChQ6HT6bBo0SJ8//332LRpE+65555KA1Oux9ChQ6HVajFu3DiUlpY6hIW6ZjabERYWVqmV2brMmTOnRse74447EBkZaVumTJlS6xrtW9SsPvvsM6SkpKBFixb46KOP8MMPP2DTpk3o27dvtf+jvtK5r845rc1zq+OXX36BSqWyzTDRvn17fPvtt/jzzz8xbNgw5OXl4X//+x/GjBlTremsxo4di7y8PKxfvx4GgwFffvmlrQ8oAOTk5KB3797Yv38/5syZg3Xr1mHTpk22/rZ1FX7++ecfJCYm4sKFC3jzzTfx3XffYdOmTXj88cfr9HXtVeffgPowf/58HDhwAM899xyKi4vx2GOPIS4uDv/++y8A6XOwY8cO/PTTT7j33ntx4MABjB49Gv3793fqQC2imvKYwU+DBg3CoEGDrri9tLQUzz//PJYvX46cnBy0b98er732mm0kpo+Pj23k5q5duyqNcASA999/H9HR0Zg/fz4A6VLSzz//jLfeeqvKS0pEVfnyyy+h0+mwceNGhxHRS5cudcrxvby8MHz4cHz22WcYNGjQFQdrWS/vp6eno2/fvg7b0tPTbduttxkZGZWOkZ6e7vC4RYsW+Omnn9CjR48qA2BNzZ8/36GlKSoqqtbHrMqaNWsQExODr776yuGS+syZM+vk9WrKeg6OHj3q0KJ58eLFarXECYIAo9GIM2fO2H6GPXv2xIoVKzBy5EgkJCQgNzfXNo3UtQwdOhR+fn744osvoFarcfnyZYfL+Nu2bcPFixfx1VdfoVevXrb1mZmZ1Tq+vdDQUHh5eVXr92/dunUoLS3Ft99+69AKfaXZFaqjup+T+mBfi/30aAaDAZmZmZUaVeLj4xEfH48XXngBv/zyC3r06IH333/fNg+tQqFAYmIiEhMT8eabb+KVV17B888/j61bt17z6hBRXfGYFtNrmTx5Mnbv3o0VK1bgwIEDuOuuuzBw4MAq/7G7kt27d1f6sCYlJWH37t3OLpc8mFKphCAIDq0Sx48fr3H3k6t58sknMXPmTLz44otX3KdLly4ICwvD+++/7zCX5YYNG3D48GHb7ACRkZG44YYb8L///a/SVDOHDh1yOOaoUaNgMpnw0ksvVXo9o9FY5R98V9O5c2eHbhQV+7Q6i7WVy76F8rfffnOZz3ZiYiJUKlWlaY/ee++9aj3f+u/WjBkzHNYPGzYMDzzwAI4fP46uXbtWOctCVby8vDBixAh8//33WLx4MXx8fBzmzq3q52kwGLBo0aJqHd+eUqlEUlISvv76a5w8edK2/vDhw5WuVlX1urm5uVX+0efj41Ot38fqfk7qQ79+/aDRaPDOO+84vMePPvoIubm5tlry8vJgNBodnhsfHw+FQmF7D5cuXap0fOvsEzWZ25bI2TymxfRqTp48iaVLl+LkyZO21oInn3wSP/zwA5YuXYpXXnmlWsc5e/ZspSlFwsPDkZeXh+LiYqe0EJHnGzx4MN58800MHDgQ99xzD7Kzs7Fw4UK0bNkSBw4ccMprJCQkICEh4ar7qNVqvPbaaxg/fjx69+6NMWPG2KbBad68ue3yJwDMnTsXgwcPxi233IIJEybg0qVLePfddxEXF4eCggLbfr1798ZDDz2EuXPnIjU1FQMGDIBarUZGRgZWr16Nt99+G3feeadT3qMz3X777fjqq68wYsQIDB48GJmZmXj//ffRrl07h/cnl/DwcEyZMgXz58/H0KFDMXDgQOzfvx8bNmxASEjINVv/br/9dgwbNgwfffQRjh49iuHDh0Or1eKHH37AunXr0KtXL2zduhUzZsyodneLsWPH4pNPPsHGjRuRnJwMHx8f27bu3bsjMDAQ48aNw2OPPQZBEPDpp59ed9eE2bNn44cffkDPnj0xceJEGI1G2++f/WdmwIAB0Gg0GDJkCB566CEUFBRgyZIlCAsLw5kzZxyO2blzZyxevBgvv/wyWrZsibCwsEotokDNPifOcP78+Sq/WSs6OhrJycmYPn06Zs+ejYEDB2Lo0KFIT0/HokWL0LVrV1sf3i1btmDy5Mm46667EBsbC6PRiE8//RRKpRIjR44EIH2r3Y4dOzB48GA0a9YM2dnZWLRoERo3boxbbrnFqe+JqCYaRDBNS0uDyWRCbGysw/rS0lIEBwfLVBU1VH379sVHH32EV199FVOnTkV0dDRee+01HD9+3GnBtLpSUlLg7e2NV199Fc8884xtcvfXXnvNYW7GgQMHYvXq1XjhhRcwffp0tGjRAkuXLsU333xTaSLy999/H507d8YHH3yA5557DiqVCs2bN8fYsWPRo0ePen1/1ZWSkoKzZ8/igw8+wMaNG9GuXTt89tlnWL16daX3J5fXXnsN3t7eWLJkCX766Sd069YNP/74I2655ZZrflORIAj48ssv8dZbb2HZsmV45pln4OXlhZtvvhkbN25E//79kZycjJdeegktW7bEfffdd816+vbti8jISJw5c8bhMj4gDZBav349nnjiCbzwwgsIDAzE2LFjkZiYeF3dnjp06ICNGzdi2rRpmDFjBho3bozZs2fjzJkzDp+Z1q1bY82aNXjhhRfw5JNPIiIiAo888ghCQ0MxYcIEh2POmDEDJ06cwLx585Cfn4/evXtXGUyB6n9OnCE7O7vKKx2JiYlITk7GrFmzEBoaivfeew+PP/44goKC8OCDD+KVV16xzRGckJCApKQkrFu3DqdOnYK3tzcSEhKwYcMG2zd2DR06FMePH8fHH3+MCxcuICQkBL1798bs2bMdZt8gqm+C6Kze9S5EEASsXbvWNrJ+5cqVSE5OxsGDByt1TPf19UVERITDupSUFOTk5FS6tNqrVy906tQJCxYssK1bunQppk6d6pTRwkRENZGTk4PAwEC8/PLLtoniiYjcWYNoMe3YsSNMJhOys7PRs2fP6z5Ot27d8P333zus27RpE7p161bbEomIrqqq7kLWP5KtgziJiNydxwTTgoICHD161PY4MzMTqampCAoKQmxsLJKTk3Hfffdh/vz56NixI86fP4/NmzejQ4cOtg7j1u/MvnTpEvLz85GamgqgvEP4ww8/jPfeew9PP/00JkyYgC1btmDVqlVVTrBMRORMK1euxLJly3DbbbfB19cXP//8M5YvX44BAwa4bBcJIqKa8phL+du2bcOtt95aaf24ceOwbNkylJWV4eWXX8Ynn3yCU6dOISQkBDfffDNmz56N+Ph4AEDz5s0rTZYMOI7w3LZtGx5//HEcOnQIjRs3xosvvoiUlJQ6e19ERACwb98+PP3000hNTUVeXh7Cw8MxcuRIvPzyy/D19ZW7PCIip/CYYEpERERE7q3BzGNKRERERK6NwZSIiIiIXIJbD34ym804ffo0/Pz8qv31ckRERERUf0RRRH5+PqKioqBQXL1N1K2D6enTp9GkSRO5yyAiIiKia8jKyrrmVx+7dTD18/MDIL1Rf39/mashIiIioory8vLQpEkTW267GrcOptbL9/7+/gymRERERC6sOt0uOfiJiIiIiFwCgykRERERuQQGUyIiIiJyCW7dx5SIiIjckyiKMBqNMJlMcpdCtaRUKqFSqZwydSeDKREREdUrg8GAM2fOoKioSO5SyEm8vb0RGRkJjUZTq+MwmBIREVG9MZvNyMzMhFKpRFRUFDQaDb8kx42JogiDwYDz588jMzMTrVq1uuYk+lfDYEpERET1xmAwwGw2o0mTJvD29pa7HHICLy8vqNVqnDhxAgaDATqd7rqPxcFPREREVO9q06pGrsdZ55O/FURERETkEhhMa+LEL8ChbwBDodyVEBEREXkcBtOa+OVdYNV9wLwWwIpk4MAqoCRX7qqIiIjITTVv3hwLFiyQuwyXwWBaE2HtgICmgLEY+Hs98NV/pJD62Z3Avk+AwgtyV0hERER1QBCEqy6zZs26ruPu2bMHDz74YK1q69OnD6ZOnVqrY7gKjsqvicQXgb4vAGcPAIfXAYe+BS6kA0c3SYswBWjWA2g7FGh7O+AfJXfFRERE5ARnzpyx3V+5ciVmzJiB9PR02zpfX1/bfVEUYTKZoFJdO2aFhoY6t1A3xxbTmhIEIDJBCqiTfwcm/S7dj0wARDNwfCew4SngzbbAh/2Av7+Xu2IiIiKXJooiigzGel9EUax2jREREbZFr9dDEATb47///ht+fn7YsGEDOnfuDK1Wi59//hn//PMPhg0bhvDwcPj6+qJr16746aefHI5b8VK+IAj48MMPMWLECHh7e6NVq1b49ttva/Xz/fLLLxEXFwetVovmzZtj/vz5DtsXLVqEVq1aQafTITw8HHfeeadt25o1axAfHw8vLy8EBwejX79+KCysu7E2bDGtrdDWQOhTQK+ngMvHgcPrpdbUrN+Af/cAq+4Fxq0DmnWXu1IiIiKXVFxmQrsZG+v9dQ/NSYK3xnlR6Nlnn8Ubb7yBmJgYBAYGIisrC7fddhv+7//+D1qtFp988gmGDBmC9PR0NG3a9IrHmT17NubNm4fXX38d7777LpKTk3HixAkEBQXVuKa9e/di1KhRmDVrFkaPHo1ffvkFEydORHBwMFJSUvDHH3/gsccew6efforu3bvj0qVL2LlzJwCplXjMmDGYN28eRowYgfz8fOzcubNGgb6mGEydKbA50H2ytOSfBTY8LY3iX50CPLQD8IuQu0IiIiKqI3PmzEH//v1tj4OCgpCQkGB7/NJLL2Ht2rX49ttvMXny5CseJyUlBWPGjAEAvPLKK3jnnXfw+++/Y+DAgTWu6c0330RiYiJefPFFAEBsbCwOHTqE119/HSkpKTh58iR8fHxw++23w8/PD82aNUPHjh0BSMHUaDTijjvuQLNmzQAA8fHxNa6hJhhM64pfBDB8MXDhKJB9EFg1Tmo5VdXuO2SJiIg8jZdaiUNzkmR5XWfq0qWLw+OCggLMmjUL3333nS3kFRcX4+TJk1c9TocOHWz3fXx84O/vj+zs7Ouq6fDhwxg2bJjDuh49emDBggUwmUzo378/mjVrhpiYGAwcOBADBw60dSNISEhAYmIi4uPjkZSUhAEDBuDOO+9EYGDgddVSHexjWpc0PsDoTwGtHsj6FfjxBbkrIiIicjmCIMBbo6r3RRAEp74PHx8fh8dPPvkk1q5di1deeQU7d+5Eamoq4uPjYTAYrnoctVpd6edjNpudWquVn58f9u3bh+XLlyMyMhIzZsxAQkICcnJyoFQqsWnTJmzYsAHt2rXDu+++i9atWyMzM7NOagEYTOtecAvgjv9K93//ANi/Ut56iIiIqF7s2rULKSkpGDFiBOLj4xEREYHjx4/Xaw1t27bFrl27KtUVGxsLpVJqMVapVOjXrx/mzZuHAwcO4Pjx49iyZQsAKRT36NEDs2fPxp9//gmNRoO1a9fWWb28lF8fWg8Eej0N7JgHrJsChLcDIuq2jwYRERHJq1WrVvjqq68wZMgQCIKAF198sc5aPs+fP4/U1FSHdZGRkXjiiSfQtWtXvPTSSxg9ejR2796N9957D4sWLQIArF+/HseOHUOvXr0QGBiI77//HmazGa1bt8Zvv/2GzZs3Y8CAAQgLC8Nvv/2G8+fPo23btnXyHgC2mNafPs8CLRKlyflXjgWKL8tdEREREdWhN998E4GBgejevTuGDBmCpKQkdOrUqU5e64svvkDHjh0dliVLlqBTp05YtWoVVqxYgfbt22PGjBmYM2cOUlJSAAABAQH46quv0LdvX7Rt2xbvv/8+li9fjri4OPj7+2PHjh247bbbEBsbixdeeAHz58/HoEGD6uQ9AIAg1uWY/zqWl5cHvV6P3Nxc+Pv7y13OtRVdAv7bG8g5CbQaAIxZCSj4twERETUcJSUlyMzMRHR0NHQ6ndzlkJNc7bzWJK8xFdUn7yBg9GeASgdk/Chd2iciIiIiAAym9S8yAbj9Len+tleBIz/KWw8RERGRi2AwlcMN9wBd7gcgAl89AFyqu2kXiIiIiNwFg6lcBr4KNO4KlOQCK+8FDEVyV0REREQkKwZTuag0wF3/A3xCgXNpwPrHAfcdh0ZERERUawymctI3Au5cCghK4MAKYM+HcldEREREJBsGU7lF9wT6z5bu//AscDZN3nqIiIiIZMJg6gq6TQZiBwJmI7DvE7mrISIiIpIFg6krEATLKH0Ah74BzCZ56yEiIiKSAYOpq4jpA+j0QME54ORuuashIiKiOtCnTx9MnTpV7jJcFoOpq1BpgDZDpPsHv5a1FCIiInI0ZMgQDBw4sMptO3fuhCAIOHDgQK1fZ9myZQgICKj1cdwVg6kriRsu3fJyPhERkUu5//77sWnTJvz777+Vti1duhRdunRBhw4dZKjMszCYupLo3oAuACjMBk78Inc1RERE9UMUAUNh/S81mD/89ttvR2hoKJYtW+awvqCgAKtXr8b999+PixcvYsyYMWjUqBG8vb0RHx+P5cuXO/VHdfLkSQwbNgy+vr7w9/fHqFGjcO7cOdv2/fv349Zbb4Wfnx/8/f3RuXNn/PHHHwCAEydOYMiQIQgMDISPjw/i4uLw/fffO7W+2lLJXQDZUWmAtrcDf34GHPpamkqKiIjI05UVAa9E1f/rPnca0PhUa1eVSoX77rsPy5Ytw/PPPw9BEAAAq1evhslkwpgxY1BQUIDOnTvjmWeegb+/P7777jvce++9aNGiBW688cZal2s2m22hdPv27TAajZg0aRJGjx6Nbdu2AQCSk5PRsWNHLF68GEqlEqmpqVCr1QCASZMmwWAwYMeOHfDx8cGhQ4fg6+tb67qcicHU1bQbYQmm3wCD5gEKpdwVEREREYAJEybg9ddfx/bt29GnTx8A0mX8kSNHQq/XQ6/X48knn7Tt/+ijj2Ljxo1YtWqVU4Lp5s2bkZaWhszMTDRp0gQA8MknnyAuLg579uxB165dcfLkSTz11FNo06YNAKBVq1a25588eRIjR45EfHw8ACAmJqbWNTkbg6mribFezj8PnNgFRPeSuyIiIqK6pfaWWi/leN0aaNOmDbp3746PP/4Yffr0wdGjR7Fz507MmTMHAGAymfDKK69g1apVOHXqFAwGA0pLS+HtXbPXuZLDhw+jSZMmtlAKAO3atUNAQAAOHz6Mrl27Ytq0aXjggQfw6aefol+/frjrrrvQokULAMBjjz2GRx55BD/++CP69euHkSNHuly/WPYxdTVKNdCWo/OJiKgBEQTpknp9L5bL8TVx//3348svv0R+fj6WLl2KFi1aoHfv3gCA119/HW+//TaeeeYZbN26FampqUhKSoLBYHD2T+yKZs2ahYMHD2Lw4MHYsmUL2rVrh7Vr1wIAHnjgARw7dgz33nsv0tLS0KVLF7z77rv1Vlt1MJi6Iuvo/MPfAiajrKUQERFRuVGjRkGhUOCLL77AJ598ggkTJtj6m+7atQvDhg3D2LFjkZCQgJiYGBw5csRpr922bVtkZWUhKyvLtu7QoUPIyclBu3btbOtiY2Px+OOP48cff8Qdd9yBpUuX2rY1adIEDz/8ML766is88cQTWLJkidPqcwZeyndF0b0Br8Dyy/kxveWuiIiIiAD4+vpi9OjRmD59OvLy8pCSkmLb1qpVK6xZswa//PILAgMD8eabb+LcuXMOobE6TCYTUlNTHdZptVr069cP8fHxSE5OxoIFC2A0GjFx4kT07t0bXbp0QXFxMZ566inceeediI6Oxr///os9e/Zg5MiRAICpU6di0KBBiI2NxeXLl7F161a0bdu2tj8Sp2KLqSuyv5x/6GtZSyEiIiJH999/Py5fvoykpCRERZXPJvDCCy+gU6dOSEpKQp8+fRAREYHhw4fX+PgFBQXo2LGjwzJkyBAIgoBvvvkGgYGB6NWrF/r164eYmBisXLkSAKBUKnHx4kXcd999iI2NxahRozBo0CDMnj0bgBR4J02ahLZt22LgwIGIjY3FokWLnPIzcRZBFGswiVcdevXVVzF9+nRMmTIFCxYsqNZz8vLyoNfrkZubC39//7otsL4d3Qx8dgfgHQI8kQ4o2bhNRETur6SkBJmZmYiOjoZOp5O7HHKSq53XmuQ1l2gx3bNnDz744AOXGxkmq+hegFcQUHQBOPGz3NUQERER1TnZg2lBQQGSk5OxZMkSBAYGyl2O6+DofCIiImpgZA+mkyZNwuDBg9GvX79r7ltaWoq8vDyHxaNxdD4RERE1ILIG0xUrVmDfvn2YO3dutfafO3eu7ZsV9Hq9wwSzHqm59XL+ReD4TrmrISIiIqpTsgXTrKwsTJkyBZ9//nm1Oz9Pnz4dubm5tsV+Hi+PpFQB7YZK9zk6n4iIPIiLjL0mJ3HW+ZQtmO7duxfZ2dno1KkTVCoVVCoVtm/fjnfeeQcqlQomk6nSc7RaLfz9/R0Wj9duuHR7iJfziYjI/anVagBAUVGRzJWQM1nPp/X8Xi/Z5iBKTExEWlqaw7rx48ejTZs2eOaZZ6BUKmWqzMU07wl4B1su5+8AWvSVuyIiIqLrplQqERAQgOzsbACAt7e37ZuTyP2IooiioiJkZ2cjICCg1vlNtmDq5+eH9u3bO6zz8fFBcHBwpfUNmlIFtB0K7F0qjc5nMCUiIjcXEREBALZwSu4vICDAdl5rg7O2u4O44VIwPbwOGDxfmkqKiIjITQmCgMjISISFhaGsrEzucqiW1Gq10650u1Qw3bZtm9wluKZmt0jfAFV0AcjcAbRMlLsiIiKiWlMqley6Rw5kn8eUqoGj84mIiKgBYDB1F3EjpNvD6wATL3sQERGR52EwdRfNegA+oUDxZSBzu9zVEBERETkdg6m7UCil0fmANDqfiIiIyMO41OAnV7dsVyYysgsQFeCFxoFeiAqQlnA/LVTKesj4cSOAPz6SLuff/hZH5xMREZFHYTCtgc1/Z2NnxoVK65UKARH+OkQF6NAooDywNgrwQqdmgdB7OSlANusO+IQBhdnAse1Aq37OOS4RERGRC2AwrYF7bmyKjk0CcCqnBKdzinEqpxhncotRZhJxyvJ4Dy47PCfAW40Zt7fDiI6Nav/NFgqlNDp/z4fAobUMpkRERORRBFEURbmLuF55eXnQ6/XIzc2Fv7+/LDWYzSIuFJTi35xinLYspy4X41ROCdLP5SHrUjEAoFdsKF4Z0R6NA71r94LHfwaWDQZ0AcCTGYBKU/s3QURERFRHapLXGEzrUJnJjP/uOIa3N2fAYDTDW6PE00mtcW+35lAqrrP11GwC5reRLucnrwFa9Xdu0UREREROVJO8xlH5dUitVGDSrS2xYUpP3Ng8CEUGE2atO4S73v8FGefyr++gCiXQbph0n6PziYiIyIMwmNaDFqG+WPHgzXh5eHv4alXYdzIHg9/5GW//JLWk1pg1mGZsBNy3wZuIiIjIAYNpPVEoBIy9uRk2TeuFxDZhMJjMeOunIxjy7s9Izcqp2cEadwEEJVB4Hsg7XSf1EhEREdU3BtN6Fqn3wofjuuCdMR0R7KNB+rl83LFoF15afwhFBmP1DqL2AsLaSvdP/1l3xRIRERHVIwZTGQiCgKEJUdg0rTdGdGwEswh89HMmkhbsQNalouodJPIG6fZMal2VSURERFSvGExlFOSjwVujb8DS8V3RKMALWZeK8eoPf1fvyVE3SLenU+uqPCIiIqJ6xWDqAm5tHYYPx3WBIADfHTiDtH9zr/2kqI7S7ZlUDoAiIiIij8Bg6iLaRvpj+A2NAADzNlaj1TQ8jgOgiIiIyKMwmLqQx/vFQqUQsDPjAn7558LVd7YfAMV+pkREROQBGExdSNNgb9xzU1MAwLwf0nHNL+WyDoBiP1MiIiLyAAymLmZy35bwUiuRmpWDHw+du/rO1gFQbDElIiIiD8Bg6mLC/HS4/5ZoAMAbG9NhMl+l1dS+xZQDoIiIiMjNMZi6oP/0ioHeS42M7AKs/fPUlXeMaG8ZAJUN5J+pvwKJiIiI6gCDqQvSe6kxsU8LAMBbm46g1Giqeke1FxDaRrrPfqZERETk5hhMXdS47s0R7q/FqZxifPHbySvvyH6mRERE5CEYTF2UTq3ElMRYAMB7W46ioNRY9Y62fqZ/1k9hRERERHWEwdSF3dWlMaJDfHCx0ICPdmZWvZP9V5NyABQRERG5MQZTF6ZWKvDEAKnVdMnOY7hUaKi8U3h7QFBwABQRERG5PQZTF3db+0jERfmjoNSIRVuPVt5B480BUEREROQRGExdnEIh4OmBUvD85NcTOJ1TXHknaz9TDoAiIiIiN8Zg6gZ6tQrBzTFBMBjNePunjMo72PczJSIiInJTDKZuQBDKW01X783C0ewCxx2iOkq3bDElIiIiN8Zg6iY6NQ1E/3bhMIvAm5vSHTdaB0AVnAPyOACKiIiI3BODqRt5Kqk1BAH4Pu0s9mfllG+wHwDFVlMiIiJyUwymbiQ23A93dGwMAHh9Y4VWU9tE+6n1WhMRERGRszCYupmp/VpBrRTw89EL2HX0QvkGfjUpERERuTkGUzfTJMgbyTc1AwC8telI+Qa2mBIREZGbYzB1Q4/0aQEA+OPEZZzPL5VWRsRbBkCd5QAoIiIicksMpm4o3F+HuCh/AMDPR89LKzXeQEhr6T4v5xMREZEbYjB1U71iQwEAO45U0c+Ul/OJiIjIDTGYuqleraRgujPjPMxmUVrJryYlIiIiN8Zg6qY6NwuEj0aJCwUGHDqTJ61kiykRERG5MQZTN6VRKdCtRTAAYEeGpZ+p/QCo/LMyVkdERERUcwymbqy8n6l1AJQPEBIr3WerKREREbkZBlM3Zu1nuvfEZRSWGqWV7GdKREREborB1I01D/FB0yBvlJlE7P7norSS/UyJiIjITTGYurlesSEA7PqZRnWUbtliSkRERG6GwdTNWS/n2/qZWgdA5Z8B8s/JWBkRERFRzTCYurluLYKhUgg4frEIJy8WOQ6AYqspERERuREGUzfnp1OjU7NAAMB26+V86wCo03/KUxQRERHRdWAw9QC9K04bxQFQRERE5IYYTD2AtZ/p7n8uosxk5pRRRERE5JYYTD1AXJQ/gn00KCg1Yt+Jy9IAKAgcAEVERERuhcHUAygUAm5pZTdtlNaXA6CIiIjI7TCYeojyaaMuSCvYz5SIiIjcDIOph+hpmWj/r9O5uFhQyn6mRERE5HZkDaaLFy9Ghw4d4O/vD39/f3Tr1g0bNmyQsyS3FeanQ9tIf4gi8PPRC2wxJSIiIrcjazBt3LgxXn31Vezduxd//PEH+vbti2HDhuHgwYNyluW2rF9Puv3IeSCiA6QBUKeBgmx5CyMiIiKqBlmD6ZAhQ3DbbbehVatWiI2Nxf/93//B19cXv/76a5X7l5aWIi8vz2Ghcr0t/Ux3ZlyAqPEBQlpJG9hqSkRERG7AZfqYmkwmrFixAoWFhejWrVuV+8ydOxd6vd62NGnSpJ6rdG2dmwfCS63E+fxSHD6Tz36mRERE5FZkD6ZpaWnw9fWFVqvFww8/jLVr16Jdu3ZV7jt9+nTk5ubalqysrHqu1rVpVUp0axEMwDJtlK2fKb+alIiIiFyf7MG0devWSE1NxW+//YZHHnkE48aNw6FDh6rcV6vV2gZKWRdy1Ms6n+mR8+UtpryUT0RERG5A9mCq0WjQsmVLdO7cGXPnzkVCQgLefvttuctyW71ipX6mfxy/jKLgduAAKCIiInIXsgfTisxmM0pLS+Uuw21Fh/igcaAXDCYzfj1l4AAoIiIichuyBtPp06djx44dOH78ONLS0jB9+nRs27YNycnJcpbl1gRBsLWa7jhygQOgiIiIyG3IGkyzs7Nx3333oXXr1khMTMSePXuwceNG9O/fX86y3F7515Oe50T7RERE5DZUcr74Rx99JOfLe6zuLYOhVAg4dqEQ2b5tEAawxZSIiIhcnsv1MaXa89ep0alpAABga14kAAHIOwUUnJe1LiIiIqKrYTD1UNbL+VuOFQHBLaWVbDUlIiIiF8Zg6qGsA6B+OXoR5oh4aeXZNBkrIiIiIro6BlMP1b6RHoHeauSXGnFa01xaef5vWWsiIiIiuhoGUw+lVAi4xXI5f29RuLQy+7CMFRERERFdHYOpB7N+PemG7EBpxYUjgNkkY0VEREREV8Zg6sGs/Uw3nfWGqNIBxhLg8nF5iyIiIiK6AgZTDxbur0ObCD+YRAXyfKKllexnSkRERC6KwdTDWVtNj6KxtIL9TImIiMhFMZh6OOt8pr8VhEkr2GJKRERELorB1MN1aR4InVqBfcUR0opsBlMiIiJyTQymHk6nVuKm6GAcES2X8jkyn4iIiFwUg2kDcEOTAGSJoTAIWsBUClzKlLskIiIiokoYTBuADo31EKHACcHSanqeA6CIiIjI9TCYNgDxjfQAgLSySGkF+5kSERGRC2IwbQDC/HUI99fiiJktpkREROS6GEwbiPhGAeUDoNhiSkRERC6IwbSBiG+kLw+mFzMAk1HegoiIiIgqYDBtIDo01uOUGIJiaAGTAbh0TO6SiIiIiBwwmDYQ7RtJI/OPmBtJK9jPlIiIiFwMg2kDEeqnRaRehwz2MyUiIiIXVaNgOm/ePBQXF9se79q1C6WlpbbH+fn5mDhxovOqI6eKb6RniykRERG5rBoF0+nTpyM/P9/2eNCgQTh16pTtcVFRET744APnVUdO5TAAii2mRERE5GJqFExFUbzqY3Jt8Y31yLDOZXrxKGAqk7cgIiIiIjvsY9qAxDfS4xRCUCDqAHMZcPEfuUsiIiIismEwbUCCfbVoFOCNoyL7mRIREZHrUdX0CR9++CF8fX0BAEajEcuWLUNISAgAOPQ/JdcU30iPI+mNcYPiH6mfaZzcFRERERFJahRMmzZtiiVLltgeR0RE4NNPP620D7mu+MZ6HPnb0s+ULaZERETkQmoUTI8fP15HZVB9iW+kx0ccmU9EREQuiH1MGxhpLlMpmIqX/gGMpdd4BhEREVH9qFEw3b17N9avX++w7pNPPkF0dDTCwsLw4IMPOky4T64n0EcDZUAj5IleEMxGadooIiIiIhdQo2A6Z84cHDx40PY4LS0N999/P/r164dnn30W69atw9y5c51eJDlXhyYB5SPzs9nPlIiIiFxDjYJpamoqEhMTbY9XrFiBm266CUuWLMG0adPwzjvvYNWqVU4vkpyrvd3lfJxnP1MiIiJyDTUKppcvX0Z4eLjt8fbt2zFo0CDb465duyIrK8t51VGd6NAoABm2AVBsMSUiIiLXUKNgGh4ejszMTACAwWDAvn37cPPNN9u25+fnQ61WO7dCcrr4RnocsQRT0zkGUyIiInINNQqmt912G5599lns3LkT06dPh7e3N3r27GnbfuDAAbRo0cLpRZJz6b3VKPRvBQBQ5GQCZSUyV0RERERUw2D60ksvQaVSoXfv3liyZAn++9//QqPR2LZ//PHHGDBggNOLJOeLbBKNXNEbgmgGLmbIXQ4RERFRzSbYDwkJwY4dO5CbmwtfX18olUqH7atXr4afn59TC6S6Ed84AEfSG6OrcESaaD8iXu6SiIiIqIGrUTCdMGFCtfb7+OOPr6sYqj8dGumRYW6Mrooj/GpSIiIicgk1CqbLli1Ds2bN0LFjR4iiWFc1UT2Ia6THj5YBUIYzh6C5xv5EREREda1GwfSRRx7B8uXLkZmZifHjx2Ps2LEICgqqq9qoDum91MjzawGUAKazh+Quh4iIiKhmg58WLlyIM2fO4Omnn8a6devQpEkTjBo1Chs3bmQLqhvSNWov3RacBMqKZa6GiIiIGroaBVMA0Gq1GDNmDDZt2oRDhw4hLi4OEydORPPmzVFQUFAXNVIdad60OS6LvhAgAheOyF0OERERNXA1DqYOT1YoIAgCRFGEyWRyVk1UT+IbB9om2kc2v5qUiIiI5FXjYFpaWorly5ejf//+iI2NRVpaGt577z2cPHkSvr6+dVEj1ZH2jfyRYW4EACg+/ZfM1RAREVFDV6PBTxMnTsSKFSvQpEkTTJgwAcuXL0dISEhd1UZ1zE+nxiXvFoBhMwr//QtechdEREREDVqNgun777+Ppk2bIiYmBtu3b8f27dur3O+rr75ySnFU94TwtkAWoL6YLncpRERE1MDVKJjed999EAShrmohGQQ27wBkAX4lpwFDEaDxlrskIiIiaqBqPME+eZZW0dG4uMMPwUI+cCEdiOood0lERETUQNVqVD65v7hGemRYRubnZ6XJXA0RERE1ZAymDZyvVoVz2uYAgEvHD8hbDBERETVoDKaEsqDWAADzucMyV0JEREQNGYMpwaux9NWkvnlHZa6EiIiIGjIGU0JUK2nAU6jxLFDKr5UlIiIiecgaTOfOnYuuXbvCz88PYWFhGD58ONLTOZ9mfYuNbo4Loj8A4NJJDoAiIiIiecgaTLdv345Jkybh119/xaZNm1BWVoYBAwagsLBQzrIaHB+tClmqZgCAsxmp8hZDREREDVaN5jF1th9++MHh8bJlyxAWFoa9e/eiV69eMlXVMBX4twQup6Ho1F9yl0JEREQNlKzBtKLc3FwAQFBQUJXbS0tLUVpaanucl5dXL3U1BMrwdsDltdBcOiJ3KURERNRAuczgJ7PZjKlTp6JHjx5o3759lfvMnTsXer3etjRp0qSeq/RcwdEdAAChxcdkroSIiIgaKpcJppMmTcJff/2FFStWXHGf6dOnIzc317ZkZWXVY4WerWmbLgCASFxA9oULMldDREREDZFLBNPJkydj/fr12Lp1Kxo3bnzF/bRaLfz9/R0Wcg4vfQguCoEAgOOH98lcDRERETVEsgZTURQxefJkrF27Flu2bEF0dLSc5TR4F71jAACXT/CrSYmIiKj+yTr4adKkSfjiiy/wzTffwM/PD2fPngUA6PV6eHl5yVlag2QMbg0U7oV47pDcpRAREVEDJGuL6eLFi5Gbm4s+ffogMjLStqxcuVLOshosH8tXk+oLjkIURZmrISIiooZG1hZThh/XEtHyBuAXoLk5C2fzShCpZ6s1ERER1R+XGPxErkEbGQcAiBQu4fAxznhARERE9YvBlMp5BSBXFQIAOPfPfpmLISIiooaGwZQcFOpbAgCKTx+UuRIiIiJqaBhMyYEqQrqcr7t8hH2AiYiIqF4xmJKDwObSV5M2MZ7Av5eLZa6GiIiIGhIGU3KgtrSYtlGcxP6syzJXQ0RERA0Jgyk5imgPE5QIFfKQ+c/fcldDREREDQiDKTlSeyFX3wYAYDrxu8zFEBERUUPCYEqVKJp2BQAEXd4Po8ksczVERETUUDCYUiX+LbsDAOKRgYzsApmrISIiooaCwZQqUTSRWkzbCceRdjxb5mqIiIiooWAwpcoCo1GoCoRWMOLC0T1yV0NEREQNBIMpVSYIKAy9AQCgPL1X3lqIiIiowWAwpSp5xdwMAGhU8BeKDEaZqyEiIqKGgMGUquTXohsA4AZFBg6ezpO5GiIiImoIGEypao06wQwBjYULyDh6RO5qiIiIqAFgMKWqaf1wyacFAKDwGCfaJyIiorrHYEpXZIzsDADwyd4ncyVERETUEDCY0hX5t+oBAGhhOIxLhQaZqyEiIiJPx2BKV+RtGZnfQTiGAycvyFwNEREReToGU7qy4FYoVvjCSzDgVDrnMyUiIqK6xWBKV6ZQ4FJgPADAdPI3mYshIiIiT8dgSlelbHojACDo8n6IoihzNUREROTJGEzpqoJbdwcAtDMdwb+Xi2WuhoiIiDwZgyldldrSYhqjOIuDRzNlroaIiIg8GYMpXZ13EC5omwAALh/ZLXMxRERE5MkYTOmaCkI7AQDUZ/6QuRIiIiLyZAymdE3W+UwjCw7CaDLLXA0RERF5KgZTuqaQNtI3QMUjAxnn8mSuhoiIiDwVgyldkyI8DiWCFv5CMTIP75O7HCIiIvJQDKZ0bUoVsn3jAADFmb/KXAwRERF5KgZTqhZjVGcAgHf2nzJXQkRERJ6KwZSqJTBWmmg/puQwigxGmashIiIiT8RgStUSGCsNgGol/IvDx0/JXA0RERF5IgZTqh6/cFxQRUAhiDh3+Be5qyEiIiIPxGBK1XYpMAEAYDr5u8yVEBERkSdiMKVqUzXtCgAIvrxf5kqIiIjIEzGYUrWFtesJAGhjSsfF/BKZqyEiIiJPw2BK1ebbrCMMUCFIKEBGeprc5RAREZGHYTCl6lNpcdorFgCQc2SXzMUQERGRp2EwpRopCu0EAFCf2StzJURERORpGEypRrxbdAMAROb/BVEUZa6GiIiIPAmDKdVIZHtpAFQr8QROZV+UuRoiIiLyJAymVCPaoKa4pAiCWjDhxF+caJ+IiIich8GUakYQcNavPQCgOPNXmYshIiIiT8JgSjVmjOoCAPA9nypvIURERORRGEypxoJadwcAxJQcgtFokrkaIiIi8hQMplRjUW26wSgqECZcxrFjGXKXQ0RERB6CwZRqTKHzRZYmBgCQfXinzNUQERGRp2AwpetyOShBupP1u7yFEBERkcdgMKXromp6IwAg6PIBmSshIiIiT8FgStclMq4XAKCF8R8UFRXKXA0RERF5AgZTui6hzdoiF77QCmU4fvA3ucshIiIiD8BgStdHEHDSKw4AkJvBb4AiIiKi2pM1mO7YsQNDhgxBVFQUBEHA119/LWc5VENF4R0BAOoze2WuhIiIiDyBrMG0sLAQCQkJWLhwoZxl0HXyiekGAIgqOChzJUREROQJVHK++KBBgzBo0CA5S6BaaNKhJ8ybBUThHC6dy0JQeBO5SyIiIiI35lZ9TEtLS5GXl+ewkHz0AcE4oZTC6Kn9m2WuhoiIiNydWwXTuXPnQq/X25YmTdhCJ7esoO4AgIB9iwFRlLkaIiIicmduFUynT5+O3Nxc25KVlSV3SQ2eX+ITKBS1aFLyN0oOrJW7HCIiInJjbhVMtVot/P39HRaS1w1tWmGNZjgAwPDjbMBklLcgIiIicltuFUzJ9QiCgNIbJ+KS6Av/wuNA6udyl0RERERuStZgWlBQgNTUVKSmpgIAMjMzkZqaipMnT8pZFtXQ0BvbYJFpOADAuOUVoKxY3oKIiIjILckaTP/44w907NgRHTtKE7VPmzYNHTt2xIwZM+Qsi2ooQq/DiZgxOCUGQ1V4Fvh9idwlERERkRuSNZj26dMHoihWWpYtWyZnWXQdRnRtgQXGkQAAced8oDhH3oKIiIjI7bCPKTlFYtswbNX0RYa5EYSSHOCXd+UuiYiIiNwMgyk5hValxO0dm+IN4yhpxa+LgPxz8hZFREREboXBlJxmVJcm2GjuglRzS6CsCNjxutwlERERkRthMCWnaRflj7goPV413i2t2LsUuJQpb1FERETkNhhMyalGdWmCX83t8IeqE2A2AltfkbskIiIichMMpuRUw26IgkapwMxCaYQ+0lYDZ9PkLYqIiIjcAoMpOVWAtwb948JxUIxGWkAiABHYPEfusoiIiMgNMJiS043q0gQA8FzOMIiCEsj4ETi+S+aqiIiIyNUxmJLT3dIyBJF6HdJKQnCy+Z3Sys2zAVGUtzAiIiJyaQym5HRKhYCRnRoDAN4sHQ6odEDWb8CRH+QtjIiIiFwagynViTs7S8H020wR+Tc8IK3cPAcwm2SsioiIiFwZgynVieYhPrgxOgiiCKxQ3wHo9ED2IWmUPhEREVEVGEypztxlaTX97EAexB6PSyu3/h9gLJWxKiIiInJVDKZUZ26Lj4SPRokTF4vwR/hdgG8EkHMS2L2QA6GIiIioEgZTqjM+WhVu7xAFAFi5/yLQ5xlpw+bZwLudgR1vALmnZKyQiIiIXAmDKdWpu7pIl/O/O3AGBXH3ADc9Aqh9gEv/AFteAt6KAz4dAaStAcpKZK6WiIiI5MRgSnWqc7NAxIT4oLjMhO/+ygYGvQo8mQ4MWwg06wFABP7ZAnx5PzA/Flj/OPDvXl7qJyIiaoAYTKlOCYKAOy2tpqv/+FdaqfUDOo4Fxn8PPPYn0OtpQN8EKMkF/vgY+LAvsOhmYNfbQN5phlQiIqIGQhBF9/1fPy8vD3q9Hrm5ufD395e7HLqCc3kl6DZ3M8wisPmJ3mgR6lt5J7MZyNwOpH4BHP4WMNpd1hcU0nRTOj2gC5BuvQKqeBwAaP2l4FtxUarr5b0SERGRo5rkNVU91UQNWLi/Dn1ah2HL39lYs/dfPDOwTeWdFAqgxa3SUvIGcHAt8OfnwL+/A6IZKL4sLddLpZMCqsbXElb9AY2PFFiVakBhvVU5PrbdV0l9Y3X+0nNtt/ryxyrt9ddHREREbDGl+rEh7Qwe+Xwfwvy0+OXZvlApq9mLpKwYKM6RLvOXWG6rfGy5X5oHlOZblgLAWFxXb6kypcYxtKq9pLCqstyqvaSArNIBap3dfct6jQ+g9gY03lII1nhbHlvWq72lAE9ERORG2GJKLiexbTiCfDTIzi/FzowLuLVNWPWeqPaSFv/I63thU1l5UDUU2IVWy2NTGWA2Wm7LAJMRMBks9+22mQxAWRFQkieFX/tbQ77ltQxA0QVpqSsqr/LAqva2/HysYdbLbp1P+c/OGnwr3toCspfdrZfUqswATEREMmAwpXqhUSkw7IYoLN11HEt2HsON0UHw0dbDr59SDXgHSUtdMZssYdcusFpba8tKpP6y1qWsRFpvLJVag42llv2KAUOhFH4NRUBZoeXWslgZiy2twBfr7v0AgMbSN1dn32fXv/zWut4WhL0qBFy7W7V3eRBm4CUioqvgpXyqN+ln83HbOzthMouI0uswa2gcBsRFyF2W6zObpTDqEFiLLaG1uDy82h5bQ26xtL81HDsE4ZKqb+uaQi11a1CqAaUWUGkst1qpK4T9rUontd5W7NJg39VB41N+X6Urf55t0QKCUPfvi4iIrqgmeY3BlOrVjiPn8fzXaci6JIWg/u3CMWtoHBoFeMlcGUEUpQBbWmBp9bX01y2x77eba7curzwI24JviSUg24Vhc5m870upLQ+p1r69au/yvsAOg9kqtgpbHlsHwFUaJGdZp1AyABMRXQGDKbm0YoMJ727JwH93HIPRLMJbo8Tj/WIxvkfz6g+KIvdhNpWHVmMpYCoFjIYKt6VSH137W2OJXfeGQsf7VXV5sB6/rBiADP+sWUOr2rt8+jLrrf2UZhWnOrO2EltbkZXq8lZjhYqBl4jcHoMpuYUj5/Lx/No07DkuTQPVNtIfr4xoj45NA2WujNyaKEoD1qxB1eG2pLz7Q0le5RZgW+uwXX/hqgbJ1SelpnyxdlWwn/HBoV+vznG7LfBanq9Q2R1PbbfNEqjtW4o5CI6InITBlNyG2Sxizd5/8cqGw8gpKoMgAMk3NcVTSW2g9+Kk+OSCRFFqBbafucF+9gZDYfl0ZtapzOynOLNfV5onPcf6XGMpZGntrYqgsHRr0Feev1frC0AAINp9M5vlVhQr3IcUlnWW41i/LEPrb2k1tlvHuYCJPBKDKbmdiwWleOX7v/HlPulrS0N8tXjx9rYYmhAFgZcyqaGwhl6TofJi7fbgMGCtpEL/3goD3MxldsG3zDEEm412xy8rD9SledI2OSi15d/UJiilvrsKpaVLg+VWoXB8rNJKg+A0vpbbiovderVPeQuzbW5hS8uzkpPUENUVBlNyW7v/uYjnv07DsfOFAICbooPQobEeAd4aBHprEOSjtt0P9FEj0FsDNfulEjmPKEoB12G+3twK3RsK7Z4g2PWDFaSGVOt9K2OppcU4t/x4JbnS8azr5G4pFpSVvxRDoZT+UBDNgGiSZsiw3hfNlm2m8pZhXQDgHQh4BQFegdI0dV5BVdwGSiFZoZRaph3Ct9Jyy3/XyHMwmJJbKzWa8N/tx/Du1qMwGM3X3N9Xq7KFVB+NClq1AhqlAlq1ElqVAlqVAhqVAlqV5XFV25XW9Uq77eX7WR/rVEqolQJbcYmcyWyWvqiixNLn12y0dJewBD/bY2N5ILR2oTCWSv2AbYPkCsoHy1VaChxblE2lcr/zqxDsQqpSeiwoLH8EWP8AqLjO8lipsZtazbvyNGu26de8KrQq+5bf19rdZxcLqiUGU/IIJy4WYsNfZ3Gp0IBLhQbkFFlvy3C5yICc4jLI8dsrCIBOpbQFVa1aCrc6S9DV2QKv0hKIK4dj2/oKoVc6lhI6dfm+tuNZ1ikVDMVETmE2W2aFKKm6a4QolrdoCpYpwaytnLbWTYW0iKLUd7joElB86eq3RZfq9+uSa0uhLg+uKq3jz0ShqPDzUDq2BNvPK2w/QK+qxyrrID115cF5CnXlQXv2rdtsLHBpDKbUIJjMIvKKpZB6uciAy4VlKCozobTMBIPJjNIyM0qNZpQaTTAYq7hfZpb2s1vneGuyPMdcrZbb+qJWCuWtv/aBV62wBWL78KuxLkol1CoBWqX9OgXUltvyEF0ekKVgXHmdVqVgqzFRbZmtXQRM5bf2rcL226yDykSxwn1z+X1YHpsM5dOo2b5so6jClGvWdQXSvtaW5tJ8u9blEnl/PjVRcUaKijNVKNXlf0QIlm4StseC4zZb0Lbequy6W1TsemG3zbooVY6PHbapr9z/+Xq7b4hieb9xlZdLdgOpSV5jb29yW0qFgEAfDQJ9NHX+WqIowmAyo6TMElgtt/aPS+xuS8qkMGsfcMvDseO6kjIpGJcYzVKotqyz7ltSZoLRXP73Y5lJRJnJiAKZr0Jq7Vp9tZVCrQIaVeX11tZhrbI8UFcM0BXXORyjwj5sPSa3plAAUEhhxRWZjNJcwaXW7hH50iA80Vw5NFcK0pZwbT+/sMNXM1fxVc2mCoP1bIP3LAP1zPaD+Cx1WFmPVZIj24+r1qxdLDQ+0tdCa3yk0Gw/+LHinM/WxUao4muk7Rad3vFxh7ullmoXwmBKVA2CYG2lVAKo//9EjCazLRhbg2xVrcH2rcTWUFtmEm0huMxUHpjLTGaUmhzX27cW20K3pXW5xGhy6DphDc4okWkENwCVQrCFV3WFluCq1qlVikotxta+xRr7cGzXgqxWKqBSCtKtQoBKKUClUDjcqhUKKJUC1JZ6rN0v2KpMbk2pApSWqbxcjShKLYSVAm9x1UHYXFbewmxd7FudRbPdfWuwNkqt2mZjFS3a9v2eLdvsp4+zTilnv581VNt/aYihoDxgW79auvB8bX4w5d/ch1PX3r3D3bV4rbrBYErkBlRKBVRKBbxl/MNWFEVLyDWVB2Rbl4nyFt5Su9beimHZPvwajJW7Ujh2pyg/vv3r2DUew2gWYTSYUGQwyfeDuQprH2Gd2nJr7T+sVtrCq0apgNoafJUKaK5wX+rCcaVW5aq7b2jtAjdbl8mjCEJ5f1O4cVc+61dBW0OqrXW6wBJaRbsvy9CU33e41UqtnoKyvDuG9SulHe5X+JrpsmKXay0FGEyJqJoEQYBGJbUI+unkq8NounJ/YFuLsMkx/FZcV1bxGPb7VwjMBqNZCsAmEWVmM0zW+ybpfpnJst0swmgyOwRna9jOdYFxLkqFALVSsPQnLg+yaqVgubW0CNtagwUoFdJ26bkK2zFUCms3Dsd+xxqV8grrpeOr7UK47b5KAbXd67CVmRoUQZD6xaq9AJ+Q2h9P6wv4hdf+ODJiMCUit2JtPfZx0RlsykxSa3KJXT9kqc9w+X3brdFkC7llttur3S8f1He1/svWx/ZMZhEms4iSMjMA+bpfXI0gQAqsCimwqhT2rclSqLZ2q1ArFFCrBMs+Cmjs7l/xOVUF4yrulz9PAaUgBWaVJTirFAIUgv1jhW29RiWFe4ZrouvHYEpE5ETWcCNnqzJQ3vWiUityhdbkMqPU17jMaGkBNoswmaVAbLK0AltbjK2twmVm0XHmimt05ygzmVFmtNRiMtvCuP2gPqlmSHUBgIt2z7gWQYCtj7OmQquxpkILsrWFWmlpoVYp7PsxC9IfYQprMLa7r3BsxS7fRzqGQhCgsE5rKggQAGmdAhAg2NYrBGm9WulYo6aKxyp+kQnVEwZTIiIPZN/1wlVbl81mqXtEmUlEmdGMMrOl64RJhNFshsEo3VoDtrU7RZmle4V9i7I0QNASnK/S6mw0iQ7huMxsee2K9y3B2WTppmGy66phNFu7cVSebVEU7QYGumjL9PVQKgSH/tDWYGwN0eX3y8N1+YDBCrcO68ofqxUCFIrybiT2gVtZxXplhaBua71WVrUeV32u0m5fhSW4kzwYTImISBYKhQCtQgmtCoCLhudrMVv7F5vtp4gzOwzcs586ztZSbbJvjXYMwdZgbmuhNokwi5aAbN/X2fLYaGnltoZ1s2VKU7MoQoTlVpRa0c0iIEKUplC11G+t0X7QocHo2F/aZBZRbDahuEymH3Q9s4VVwdJ9Q1Hh1q47h2N3D7vwK1QOydZ+1Aq7FmtBkFqyrY8VivIWbenY0h8E1uOrKwZ7S6i3HluA5bsgLMcG4LDe1moOICkuAgoXGxjJYEpERHSdFAoBGoUADeSdNaMu2A80tO8KYt8VwxqcjWZzpe4eRpPdOrO5QuAu39fa+mwN19bQbbZvrbYP49YAbi5vvTaJ0jFN5gqt3JbXNYlSiDeJ5dtM5sot3lbX2u4p/nnlNrlLqITBlIiIiCpx9YGGtSWKdiFYdGyBtn9sEqXQbLIEYftAbA3Qpis93xKMzXaBWLS0ZpttrdjW+9bWbemxye449n8AWIO8/R8A1nWi5X1J78+utRzWW0jTt1oeu1ZbqYTBlIiIiBocQbBeCpe7ErLHYXZERERE5BIYTImIiIjIJTCYEhEREZFLYDAlIiIiIpfAYEpERERELoHBlIiIiIhcAoMpEREREbkEBlMiIiIicgkMpkRERETkEhhMiYiIiMglMJgSERERkUtQyV1AbYiiCADIy8uTuRIiIiIiqoo1p1lz29W4dTDNz88HADRp0kTmSoiIiIjoavLz86HX66+6jyBWJ766KLPZjNOnT8PPzw+CINT56+Xl5aFJkybIysqCv79/nb8e1R2eS8/Bc+k5eC49B8+l53DGuRRFEfn5+YiKioJCcfVepG7dYqpQKNC4ceN6f11/f39+0DwEz6Xn4Ln0HDyXnoPn0nPU9lxeq6XUioOfiIiIiMglMJgSERERkUtgMK0BrVaLmTNnQqvVyl0K1RLPpefgufQcPJeeg+fSc9T3uXTrwU9ERERE5DnYYkpERERELoHBlIiIiIhcAoMpEREREbkEBlMiIiIicgkMpjWwcOFCNG/eHDqdDjfddBN+//13uUuia9ixYweGDBmCqKgoCIKAr7/+2mG7KIqYMWMGIiMj4eXlhX79+iEjI0OeYumq5s6di65du8LPzw9hYWEYPnw40tPTHfYpKSnBpEmTEBwcDF9fX4wcORLnzp2TqWK6ksWLF6NDhw62Cbu7deuGDRs22LbzPLqnV199FYIgYOrUqbZ1PJfuY9asWRAEwWFp06aNbXt9nUsG02pauXIlpk2bhpkzZ2Lfvn1ISEhAUlISsrOz5S6NrqKwsBAJCQlYuHBhldvnzZuHd955B++//z5+++03+Pj4ICkpCSUlJfVcKV3L9u3bMWnSJPz666/YtGkTysrKMGDAABQWFtr2efzxx7Fu3TqsXr0a27dvx+nTp3HHHXfIWDVVpXHjxnj11Vexd+9e/PHHH+jbty+GDRuGgwcPAuB5dEd79uzBBx98gA4dOjis57l0L3FxcThz5oxt+fnnn23b6u1cilQtN954ozhp0iTbY5PJJEZFRYlz586VsSqqCQDi2rVrbY/NZrMYEREhvv7667Z1OTk5olarFZcvXy5DhVQT2dnZIgBx+/btoihK506tVourV6+27XP48GERgLh79265yqRqCgwMFD/88EOeRzeUn58vtmrVSty0aZPYu3dvccqUKaIo8jPpbmbOnCkmJCRUua0+zyVbTKvBYDBg79696Nevn22dQqFAv379sHv3bhkro9rIzMzE2bNnHc6rXq/HTTfdxPPqBnJzcwEAQUFBAIC9e/eirKzM4Xy2adMGTZs25fl0YSaTCStWrEBhYSG6devG8+iGJk2ahMGDBzucM4CfSXeUkZGBqKgoxMTEIDk5GSdPngRQv+dS5dSjeagLFy7AZDIhPDzcYX14eDj+/vtvmaqi2jp79iwAVHlerdvINZnNZkydOhU9evRA+/btAUjnU6PRICAgwGFfnk/XlJaWhm7duqGkpAS+vr5Yu3Yt2rVrh9TUVJ5HN7JixQrs27cPe/bsqbSNn0n3ctNNN2HZsmVo3bo1zpw5g9mzZ6Nnz57466+/6vVcMpgSkduZNGkS/vrrL4f+T+ReWrdujdTUVOTm5mLNmjUYN24ctm/fLndZVANZWVmYMmUKNm3aBJ1OJ3c5VEuDBg2y3e/QoQNuuukmNGvWDKtWrYKXl1e91cFL+dUQEhICpVJZafTZuXPnEBERIVNVVFvWc8fz6l4mT56M9evXY+vWrWjcuLFtfUREBAwGA3Jychz25/l0TRqNBi1btkTnzp0xd+5cJCQk4O233+Z5dCN79+5FdnY2OnXqBJVKBZVKhe3bt+Odd96BSqVCeHg4z6UbCwgIQGxsLI4ePVqvn0sG02rQaDTo3LkzNm/ebFtnNpuxefNmdOvWTcbKqDaio6MRERHhcF7z8vLw22+/8by6IFEUMXnyZKxduxZbtmxBdHS0w/bOnTtDrVY7nM/09HScPHmS59MNmM1mlJaW8jy6kcTERKSlpSE1NdW2dOnSBcnJybb7PJfuq6CgAP/88w8iIyPr9XPJS/nVNG3aNIwbNw5dunTBjTfeiAULFqCwsBDjx4+XuzS6ioKCAhw9etT2ODMzE6mpqQgKCkLTpk0xdepUvPzyy2jVqhWio6Px4osvIioqCsOHD5evaKrSpEmT8MUXX+Cbb76Bn5+frV+TXq+Hl5cX9Ho97r//fkybNg1BQUHw9/fHo48+im7duuHmm2+WuXqyN336dAwaNAhNmzZFfn4+vvjiC2zbtg0bN27keXQjfn5+tj7eVj4+PggODrat57l0H08++SSGDBmCZs2a4fTp05g5cyaUSiXGjBlTv59Lp47x93Dvvvuu2LRpU1Gj0Yg33nij+Ouvv8pdEl3D1q1bRQCVlnHjxomiKE0Z9eKLL4rh4eGiVqsVExMTxfT0dHmLpipVdR4BiEuXLrXtU1xcLE6cOFEMDAwUvb29xREjRohnzpyRr2iq0oQJE8RmzZqJGo1GDA0NFRMTE8Uff/zRtp3n0X3ZTxclijyX7mT06NFiZGSkqNFoxEaNGomjR48Wjx49atteX+dSEEVRdG7UJSIiIiKqOfYxJSIiIiKXwGBKRERERC6BwZSIiIiIXAKDKRERERG5BAZTIiIiInIJDKZERERE5BIYTImIiIjIJTCYEhEREZFLYDAlIvIAgiDg66+/lrsMIqJaYTAlIqqllJQUCIJQaRk4cKDcpRERuRWV3AUQEXmCgQMHYunSpQ7rtFqtTNUQEbkntpgSETmBVqtFRESEwxIYGAhAusy+ePFiDBo0CF5eXoiJicGaNWscnp+Wloa+ffvCy8sLwcHBePDBB1FQUOCwz8cff4y4uDhotVpERkZi8uTJDtsvXLiAESNGwNvbG61atcK3335bt2+aiMjJGEyJiOrBiy++iJEjR2L//v1ITk7G3XffjcOHDwMACgsLkZSUhMDAQOzZswerV6/GTz/95BA8Fy9ejEmTJuHBBx9EWloavv32W7Rs2dLhNWbPno1Ro0bhwIEDuO2225CcnIxLly7V6/skIqoNQRRFUe4iiIjcWUpKCj777DPodDqH9c899xyee+45CIKAhx9+GIsXL7Ztu/nmm9GpUycsWrQIS5YswTPPPIOsrCz4+PgAAL7//nsMGTIEp0+fRnh4OBo1aoTx48fj5ZdfrrIGQRDwwgsv4KWXXgIghV1fX19s2LCBfV2JyG2wjykRkRPceuutDsETAIKCgmz3u3Xr5rCtW7duSE1NBQAcPnwYCQkJtlAKAD169IDZbEZ6ejoEQcDp06eRmJh41Ro6dOhgu+/j4wN/f39kZ2df71siIqp3DKZERE7g4+NT6dK6s3h5eVVrP7Va7fBYEASYzea6KImIqE6wjykRUT349ddfKz1u27YtAKBt27bYv38/CgsLbdt37doFhUKB1q1bw8/PD82bN8fmzZvrtWYiovrGFlMiIicoLS3F2bNnHdapVCqEhIQAAFavXo0uXbrglltuweeff47ff/8dH330EQAgOTkZM2fOxLhx4zBr1iycP38ejz76KO69916Eh4cDAGbNmoWHH34YYWFhGDRoEPLz87Fr1y48+uij9ftGiYjqEIMpEZET/PDDD4iMjHRY17p1a/z9998ApBHzK1aswMSJExEZGYnly5ejXbt2AABvb29s3LgRU6ZMQdeuXeHt7Y2RI0fizTfftB1r3LhxKCkpwVtvvYUnn3wSISEhuPPOO+vvDRIR1QOOyiciqmOCIGDt2rUYPny43KUQEbk09jElIiIiIpfAYEpERERELoF9TImI6hh7TBERVQ9bTImIiIjIJTCYEhEREZFLYDAlIiIiIpfAYEpERERELoHBlIiIiIhcAoMpEREREbkEBlMiIiIicgkMpkRERETkEv4fHSm92M9cIdsAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "both lines decrease --> the model is learning effectively\n",
        "\n",
        "   - One line shows the training loss (how well the model fits the training data).\n",
        "   - The other line shows the validation loss (how well the model performs on unseen data).\n",
        "\n",
        "A significant gap between the training and validation losses may indicate overfitting."
      ],
      "metadata": {
        "id": "pifq1_nbKjSs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Final Performance on Validation Set"
      ],
      "metadata": {
        "id": "uKBOdh4ArD_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8) Evaluate final model performance (MSE / RMSE) on the validation set\n",
        "\n",
        "final_model.eval()\n",
        "val_mse = 0.0\n",
        "with torch.no_grad():\n",
        "    for batch_x, batch_y in val_loader:\n",
        "        preds = final_model(batch_x).squeeze()\n",
        "        loss  = criterion(preds, batch_y)\n",
        "        val_mse += loss.item()\n",
        "\n",
        "val_mse /= len(val_loader)\n",
        "val_rmse = np.sqrt(val_mse)\n",
        "\n",
        "print(f\"\\nFinal Model Validation MSE : {val_mse:.4f}\")\n",
        "print(f\"Final Model Validation RMSE: {val_rmse:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6SbwDYvrHTr",
        "outputId": "520c0e25-5a03-4758-8ca9-6a70570dcafb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Model Validation MSE : 3670067744.0000\n",
            "Final Model Validation RMSE: 60581.0840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Final Model Validation MSE: 3,670,067,744.0000**  \n",
        "  This value represents the average of the squared differences between the predicted sale prices and the actual sale prices on the validation set. Because the errors are squared, the MSE tends to be a large number. It is less intuitive to interpret on its own because its units are the square of the target variable’s units (e.g., dollars²).\n",
        "\n",
        "- **Final Model Validation RMSE: 60,581.0840**  \n",
        "  The RMSE is the square root of the MSE, bringing the error metric back to the same units as the target variable (dollars, in this case). An RMSE of approximately 60,581 means that, on average, the model’s predictions deviate from the actual sale prices by about \\$60,581.\n",
        "\n",
        "    On average, the model's predicted sale price is off by roughly \\$60,581 compared to the actual sale price.\n"
      ],
      "metadata": {
        "id": "CAkH0PvNLXdz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Predictions on test.csv"
      ],
      "metadata": {
        "id": "I6oiuVMTrN2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9) Generate Predictions\n",
        "# We can't measure MSE on test.csv, as it lacks SalePrice, but can produce predictions.\n",
        "\n",
        "test_data = pd.read_csv('test.csv')\n",
        "print(\"\\nColumns in test.csv:\")\n",
        "print(test_data.columns)\n",
        "\n",
        "# Keep the same features, minus SalePrice (which doesn't exist)\n",
        "test_data = test_data[['LotFrontage', 'LotArea', 'PoolArea',\n",
        "                       'OverallQual','OverallCond','YearBuilt',\n",
        "                       'GarageArea', 'YrSold']]\n",
        "\n",
        "# Drop rows with missing data or choose an imputation strategy\n",
        "test_data.dropna(inplace=True)\n",
        "print(\"Test data shape after dropna:\", test_data.shape)\n",
        "\n",
        "# Scale using the same scaler\n",
        "X_test = test_data.values\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_test_t = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "\n",
        "# Inference\n",
        "final_model.eval()\n",
        "with torch.no_grad():\n",
        "    test_preds = final_model(X_test_t).squeeze().numpy()\n",
        "\n",
        "print(\"Predictions on test.csv (first 10):\")\n",
        "print(test_preds[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ofE7iEiGrNDP",
        "outputId": "539f6c3b-b0df-4cdf-f0b8-3df44e17f394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Columns in test.csv:\n",
            "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
            "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
            "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
            "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
            "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
            "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
            "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
            "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
            "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
            "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
            "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
            "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
            "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
            "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
            "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
            "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
            "       'SaleCondition'],\n",
            "      dtype='object')\n",
            "Test data shape after dropna: (1231, 8)\n",
            "Predictions on test.csv (first 10):\n",
            "[184783.39 166546.83 185923.48 193353.58 202869.64 187825.33 181949.45\n",
            " 206018.92 154905.8  192090.48]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Summary of the Notebook**\n",
        "\n",
        "1. **Data Loading and Preprocessing**  \n",
        "   - **Import Libraries**: We load PyTorch, NumPy, Pandas, and other necessary libraries.  \n",
        "   - **Load `train.csv`**: We select relevant numeric columns (e.g., `LotFrontage`, `LotArea`, `PoolArea`, `OverallQual`, etc.) and drop missing values.  \n",
        "   - **Train/Validation Split**: We split the dataset into an 80% train set and a 20% validation set to track performance and avoid overfitting.  \n",
        "   - **Scaling**: We use `MinMaxScaler` on the training set, then apply it to the validation set.\n",
        "\n",
        "2. **PyTorch Dataset & DataLoader**  \n",
        "   - We convert NumPy arrays into PyTorch tensors and wrap them in `TensorDataset`s.  \n",
        "   - We create `DataLoader`s for both train and validation splits, enabling mini-batch processing.\n",
        "\n",
        "3. **Neural Network Architecture**  \n",
        "   - A simple MLP with 2 hidden layers (e.g., **64** and **32** units).  \n",
        "   - Activation function: **ReLU**.  \n",
        "   - Final output layer: single neuron for regression.\n",
        "\n",
        "4. **Training & Validation Loop**  \n",
        "   - **Loss Function**: Mean Squared Error (MSE) for regression.  \n",
        "   - **Optimizer**: `Adam` (learning rate 0.01 by default).  \n",
        "   - We track both **training loss** and **validation loss** for each epoch.  \n",
        "   - This helps us monitor if the model starts overfitting (training loss goes down but validation loss goes up).\n",
        "\n",
        "5. **Hyperparameter Tuning**  \n",
        "   - An **optional** simple grid search snippet is included.  \n",
        "   - It loops over a few choices for hidden layer sizes and learning rates.  \n",
        "   - Records validation loss for each combination to find a best configuration.\n",
        "\n",
        "6. **Final Evaluation**  \n",
        "   - We compute **MSE** and **RMSE** on the validation set.  \n",
        "   - This internal evaluation helps gauge real-world performance.\n",
        "\n",
        "7. **Inference on `test.csv`**  \n",
        "   - We load `test.csv` (which lacks `SalePrice`).  \n",
        "   - We apply the same **MinMaxScaler** (fitted on training data).  \n",
        "   - We feed the scaled test data into the final model, generating predictions.  \n",
        "   - These predictions can be used for submission to Kaggle or further external evaluation.\n",
        "\n",
        "**Key Takeaways**  \n",
        "- This notebook demonstrates **end-to-end** training of an MLP in PyTorch:  \n",
        "  1. **Data preprocessing** (filter columns, drop missing, scale).  \n",
        "  2. **Train/Validation Split** (monitor overfitting).  \n",
        "  3. **Defining and training** a neural network (2 hidden layers, ReLU).  \n",
        "  4. **Hyperparameter tuning** snippet (optional).  \n",
        "  5. **Final model evaluation** on the validation set and **prediction** on test data.  \n",
        "\n",
        "- By **incorporating a validation set**, we ensure our model generalizes and avoid relying on Kaggle’s hidden labels alone.  \n",
        "- This approach addresses common assignment objectives: feature engineering, data preprocessing, building/training a neural network, hyperparameter experimentation, and evaluation.\n"
      ],
      "metadata": {
        "id": "qX_mbJuurbQd"
      }
    }
  ]
}